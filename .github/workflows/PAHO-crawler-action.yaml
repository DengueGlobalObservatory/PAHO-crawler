name: PAHO web crawling on Github Action
on:
  workflow_dispatch:
  schedule:
    - cron: '00 08 * * *' # 08:00 am UTC every day

jobs:
  Scraping_data:
    runs-on: ubuntu-latest
    steps:
      - name: Checking out repo
        uses: actions/checkout@v3
      - name: Setting up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12.3'
      - name: Install Google Chrome Stable # STEP 1: Install Chrome
        run: |
          sudo apt-get update -y
          sudo apt-get install -y google-chrome-stable
          google-chrome-stable --version # Verify installation

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install selenium
          pip install undetected_chromedriver
          pip install setuptools
          pip install webdriver_manager

      - name: Create data directory
        run: mkdir -p ${{ github.workspace }}/data

      - name: Running the Python script
        run: python scripts/PAHOCrawler_UCver_v3.py

      - name: Commit and Push
        run: |
         git config --global user.name "github-actions[bot]"
         git config --global user.email "41898282+github-actions[bot]@users.noreply.github.com"
         git add -A
         timestamp=$(date -u)
         git commit -am "Latest data: ${timestamp}" || exit 0
         git push



